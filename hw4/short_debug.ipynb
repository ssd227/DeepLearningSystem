{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/playground/10714/hw4\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!cd /playground/10714/hw4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean\n",
    "!rm -rf ./.hypothesis\n",
    "!rm -rf ./.pytest_cache\n",
    "!rm -rf ./build\n",
    "!rm -rf ./python/needle/__pycache__\n",
    "!rm -rf ./python/needle/backend_ndarray/__pycache__\n",
    "!rm -rf ./python/needle/backend_ndarray/*.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found Python: /opt/conda/bin/python3.10 (found version \"3.10.9\") found components: Development Interpreter Development.Module Development.Embed \n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- Found pybind11: /opt/conda/lib/python3.10/site-packages/pybind11/include (found version \"2.11.1\")\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Found CUDA: /usr/local/cuda (found version \"11.7\") \n",
      "-- Found cuda, building cuda backend\n",
      "Fri Jul 28 13:45:14 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.06              Driver Version: 536.40       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070 ...    On  | 00000000:26:00.0  On |                  N/A |\n",
      "|  0%   53C    P8              35W / 255W |   2366MiB /  8192MiB |     26%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        20      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        26      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A     17577      C   /python3.10                               N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "-- Autodetected CUDA architecture(s):  7.5\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /playground/10714/hw4/build\n",
      "make[1]: Entering directory '/playground/10714/hw4/build'\n",
      "make[2]: Entering directory '/playground/10714/hw4/build'\n",
      "make[3]: Entering directory '/playground/10714/hw4/build'\n",
      "make[3]: Leaving directory '/playground/10714/hw4/build'\n",
      "make[3]: Entering directory '/playground/10714/hw4/build'\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cpu.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
      "make[3]: Leaving directory '/playground/10714/hw4/build'\n",
      "[ 50%] Built target ndarray_backend_cpu\n",
      "make[3]: Entering directory '/playground/10714/hw4/build'\n",
      "[ 75%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
      "make[3]: Leaving directory '/playground/10714/hw4/build'\n",
      "make[3]: Entering directory '/playground/10714/hw4/build'\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cuda.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
      "make[3]: Leaving directory '/playground/10714/hw4/build'\n",
      "[100%] Built target ndarray_backend_cuda\n",
      "make[2]: Leaving directory '/playground/10714/hw4/build'\n",
      "make[1]: Leaving directory '/playground/10714/hw4/build'\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.9, pytest-7.4.0, pluggy-1.0.0 -- /opt/conda/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/playground/10714/hw4/.hypothesis/examples')\n",
      "rootdir: /playground/10714/hw4\n",
      "plugins: hypothesis-6.70.0, anyio-3.7.0\n",
      "collected 1803 items / 1685 deselected / 118 selected                          \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_nd_backend.py::test_ewise_fn[cpu-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m        [  0%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cpu-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m      [  1%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cpu-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m        [  2%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cpu-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m      [  3%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cuda-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m       [  4%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cuda-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m     [  5%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cuda-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m       [  5%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cuda-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m     [  6%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cpu-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m       [  7%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cpu-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m     [  8%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cpu-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m       [  9%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cpu-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 10%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cuda-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 11%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cuda-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 11%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cuda-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 12%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cuda-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 13%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-16-16-16] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 14%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-8-8-8] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 15%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-1-2-3] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 16%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-3-4-5] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 16%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-5-4-3] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 17%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-16-16-32] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 18%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-64-64-64] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 19%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-72-72-72] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 20%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-72-73-74] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 21%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-74-73-72] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 22%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-128-128-128] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 22%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-16-16-16] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 23%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-8-8-8] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 24%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-1-2-3] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 25%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-3-4-5] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 26%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-5-4-3] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 27%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-16-16-32] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 27%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-64-64-64] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 28%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-72-72-72] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 29%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-72-73-74] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 30%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-74-73-72] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 31%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-128-128-128] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 32%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 33%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 33%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 34%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 35%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 36%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 37%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 38%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 38%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 39%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 40%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 41%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 42%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 43%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 44%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 44%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 45%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 46%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 47%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 48%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 49%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 50%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 50%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[cuda-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 51%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[cuda-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 52%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cpu-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 53%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cpu-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 54%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cpu-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 55%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cuda-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 55%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cuda-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 56%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cuda-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 57%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cpu-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 58%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cpu-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 59%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cpu-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 60%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cuda-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 61%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cuda-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 61%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cuda-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 62%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 63%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 64%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 65%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 66%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cuda-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 66%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cuda-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 67%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cuda-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 68%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cuda-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 69%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 71%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 72%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 72%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cuda-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cuda-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 74%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cuda-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 75%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cuda-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 76%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[cpu-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[cpu-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[cuda-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[cuda-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[cpu-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 80%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[cpu-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 81%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[cuda-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 82%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[cuda-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 83%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-axes0-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 83%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-axes0-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 84%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-axes1-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 85%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-axes1-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 86%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-None-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 87%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-None-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 88%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-axes0-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 88%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-axes0-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 89%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-axes1-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 90%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-axes1-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 91%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-None-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 92%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-None-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 93%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 94%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 94%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 95%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 96%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cuda-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 97%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cuda-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 98%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cuda-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m           [ 99%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cuda-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m           [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m118 passed\u001b[0m, \u001b[33m1685 deselected\u001b[0m\u001b[32m in 3.36s\u001b[0m\u001b[32m =====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nd_backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.9, pytest-7.4.0, pluggy-1.0.0 -- /opt/conda/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/playground/10714/hw4/.hypothesis/examples')\n",
      "rootdir: /playground/10714/hw4\n",
      "plugins: hypothesis-6.70.0, anyio-3.7.0\n",
      "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m34 passed\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[32m in 2.51s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.9, pytest-7.4.0, pluggy-1.0.0 -- /opt/conda/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/playground/10714/hw4/.hypothesis/examples')\n",
      "rootdir: /playground/10714/hw4\n",
      "plugins: hypothesis-6.70.0, anyio-3.7.0\n",
      "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m34 passed\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[32m in 2.69s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and backward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.9, pytest-7.4.0, pluggy-1.0.0 -- /opt/conda/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/playground/10714/hw4/.hypothesis/examples')\n",
      "rootdir: /playground/10714/hw4\n",
      "plugins: hypothesis-6.70.0, anyio-3.7.0\n",
      "collected 1803 items / 1763 deselected / 40 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m40 passed\u001b[0m, \u001b[33m1763 deselected\u001b[0m\u001b[32m in 3.66s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"flip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.9, pytest-7.4.0, pluggy-1.0.0 -- /opt/conda/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/playground/10714/hw4/.hypothesis/examples')\n",
      "rootdir: /playground/10714/hw4\n",
      "plugins: hypothesis-6.70.0, anyio-3.7.0\n",
      "collected 1803 items / 1789 deselected / 14 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-4-1-1-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-4-1-1-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m14 passed\u001b[0m, \u001b[33m1789 deselected\u001b[0m\u001b[32m in 2.45s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nn_conv_backward\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playground\n",
    "    测试一些函数和算子的具体功能\n",
    "* ops/Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndim = 3\n",
    "axis = 1\n",
    "tuple([a for a in range(ndim) if a != axis]) + (axis,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npz (2, 2) \n",
      " [[2 1]\n",
      " [1 2]]\n",
      "npz_max (2,) \n",
      " [2 2]\n",
      "np_all_max (2, 2) \n",
      " [[2 2]\n",
      " [2 2]]\n",
      "npz_mask (2, 2) \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./python')\n",
    "\n",
    "import numpy\n",
    "import needle as ndl\n",
    "\n",
    "\n",
    "def calc_numpy_max_mask(axis, keepdims, npz):\n",
    "    \"\"\"\n",
    "        使用numpy计算，逻辑上是正确的。但是由于是cpu计算，会拖慢整体计算速度。\n",
    "        先保证逻辑上的正确性吧。\n",
    "    \"\"\"\n",
    "    npz_max = numpy.max(npz, axis=axis, keepdims=keepdims)\n",
    "    print(\"npz_max\",npz_max.shape, \"\\n\", npz_max)\n",
    "\n",
    "    max_axes = axis\n",
    "    if axis is None:\n",
    "        max_axes = list(range(len(npz.shape)))\n",
    "    max_shape = list(npz.shape)\n",
    "    for ax in max_axes:\n",
    "        max_shape[ax] = 1\n",
    "                \n",
    "    if keepdims == False:\n",
    "        npz_max = npz_max.reshape(max_shape)\n",
    "\n",
    "    np_all_max =  numpy.broadcast_to(npz_max, npz.shape)\n",
    "    print(\"np_all_max\", np_all_max.shape,\"\\n\",np_all_max)\n",
    "\n",
    "    npmask =  numpy.float32(npz == np_all_max)\n",
    "    # 注意维度相同的两个max值需要均分\n",
    "    if axis == None:\n",
    "        npmask = npmask / numpy.sum(npmask, axis=axis)\n",
    "    else:\n",
    "        npmask /= numpy.sum(npmask, axis=axis, keepdims=True)\n",
    "    return npmask\n",
    "\n",
    "# 使用numpy计算max id\n",
    "axis = (1,)\n",
    "# axis = None\n",
    "keepdims = False\n",
    "# Z = numpy.random.rand(2,3,2)\n",
    "Z = numpy.array([[2,1],[1,2]]) \n",
    "print(\"npz\", Z.shape, \"\\n\",Z)\n",
    "\n",
    "mask = calc_numpy_max_mask(axis, keepdims,Z)\n",
    "mask = ndl.Tensor(ndl.NDArray(mask), requires_grad=False)\n",
    "print(\"npz_mask\", mask.shape,\"\\n\",mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [1., 2.]], requires_grad=True)\n",
      "tensor([2., 2.], grad_fn=<MaxBackward0>)\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.nn.Parameter(torch.randn(3, 4))\n",
    "a = torch.tensor([[1,2],[1,2]], requires_grad =True, dtype=torch.float32)\n",
    "print(a)\n",
    "\n",
    "y = torch.max(a, dim=1).values\n",
    "print(y)\n",
    "\n",
    "torch.sum(y).backward()\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      " [[2. 2.]\n",
      " [1. 2.]] \n",
      "y\n",
      " [[2.]]\n",
      "\n",
      "[[0.33333334 0.33333334]\n",
      " [0.         0.33333334]]\n"
     ]
    }
   ],
   "source": [
    "# test ops.Max()\n",
    "import needle as ndl\n",
    "a = [[2,2],[1,2]]\n",
    "\n",
    "keepdims = True\n",
    "axis = None\n",
    "device = ndl.backend_ndarray.cuda()\n",
    "a = ndl.Tensor(ndl.NDArray(a, device=device), requires_grad=True, device=device)\n",
    "\n",
    "y = ndl.ops.max(a, axis=axis, keepdims=keepdims)\n",
    "print(\"a\\n\", a, '\\ny\\n', y)\n",
    "y.backward()\n",
    "\n",
    "print()\n",
    "print(a.grad)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test nn.LogSumExp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('./python')\n",
    "\n",
    "import numpy\n",
    "import needle as ndl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepdims = False\n",
    "axis = 1\n",
    "a = [[2.0,2.0],[1.0,2.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6931, 2.3133], grad_fn=<AddBackward0>)\n",
      "grad-torch-搭积木 tensor([[0.5000, 0.5000],\n",
      "        [0.2689, 0.7311]])\n"
     ]
    }
   ],
   "source": [
    "# 使用pytorch做对比\n",
    "def torch_LSE(Z, axis=None, keepdims=False):\n",
    "    \n",
    "    if axis == None:\n",
    "        max_Z1 = torch.max(Z)\n",
    "        max_Z2 = max_Z1\n",
    "    else:\n",
    "        max_Z1 = torch.max(Z, dim=axis, keepdim=True).values\n",
    "        max_Z2 = torch.max(Z, axis=axis, keepdims=keepdims).values\n",
    "\n",
    "    return torch.log(torch.sum(torch.exp(Z-max_Z1), dim=axis, keepdims=keepdims)) + max_Z2\n",
    "\n",
    "x = torch.tensor(a, requires_grad=True, dtype=torch.float32)\n",
    "y = torch_LSE(x,axis=axis, keepdims=keepdims)\n",
    "torch.sum(y).backward()\n",
    "\n",
    "print(y)\n",
    "print(\"grad-torch-搭积木\", x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6931, 2.3133], grad_fn=<LogsumexpBackward0>)\n",
      "grad-torch-func tensor([[0.5000, 0.5000],\n",
      "        [0.2689, 0.7311]])\n"
     ]
    }
   ],
   "source": [
    "# 使用pytorch做对比\n",
    "\n",
    "x = torch.tensor(a, requires_grad=True, dtype=torch.float32)\n",
    "y = torch.logsumexp(x, dim=axis,keepdim=keepdims)\n",
    "torch.sum(y).backward()\n",
    "\n",
    "print(y)\n",
    "print(\"grad-torch-func\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6931472 2.3132617]\n",
      "grad-nn [[0.5        0.5       ]\n",
      " [0.26894143 0.7310586 ]]\n"
     ]
    }
   ],
   "source": [
    "# needle 使用nn实现\n",
    "lse = ndl.nn.LogSumExp()\n",
    "device = ndl.backend_ndarray.cuda()\n",
    "\n",
    "x = ndl.Tensor(ndl.NDArray(a, device=device), requires_grad=True, device=device)\n",
    "\n",
    "y = lse.forward(x, axis=axis, keepdims=keepdims)\n",
    "y.backward()\n",
    "\n",
    "print(y)\n",
    "print(\"grad-nn\", x.grad)\n",
    "\n",
    "# 侧面佐证max实现的是对的，nn.LogSumExp 也没有什么问题。但是有个问题todo，summation不支持keepdims=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      " [2.6931472 2.3132617]\n",
      "grad-ops [[0.75       0.75      ]\n",
      " [0.26894143 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# needle 使用ops实现\n",
    "device = ndl.backend_ndarray.cuda()\n",
    "x1 = ndl.Tensor(ndl.NDArray(a, device=device), requires_grad=True, device=device)\n",
    "\n",
    "y = ndl.ops.logsumexp(x1, axes=axis)\n",
    "y.backward()\n",
    "\n",
    "print(\"y\\n\",y)\n",
    "print(\"grad-ops\", x1.grad)\n",
    "\n",
    "# max的反向细节存在不确定性\n",
    "# 但是使用nn.LogSumExp 时又与pytorch一致。\n",
    "    # 大致上应该时数据类型导致在max时的行为不一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [1., 2.]], requires_grad=True)\n",
      "z2 tensor([[2., 2.],\n",
      "        [1., 2.]], requires_grad=True)\n",
      "max mask tensor([[0],\n",
      "        [1]])\n",
      "\n",
      "ops.logsumexp \n",
      "d_log\n",
      " tensor([0.5000, 0.7311]) \n",
      "d_sum\n",
      " tensor([[0.5000, 0.5000],\n",
      "        [0.7311, 0.7311]]) \n",
      "d_exp\n",
      " tensor([[0.5000, 0.5000],\n",
      "        [0.2689, 0.7311]]) \n",
      "dz1\n",
      " tensor([[1., 0.],\n",
      "        [0., 1.]]) \n",
      "dz\n",
      " tensor([[0.5000, 0.5000],\n",
      "        [0.2689, 0.7311]]) \n",
      "dzmax\n",
      " tensor([[-1.,  0.],\n",
      "        [ 0., -1.]]) \n",
      "dz2\n",
      " tensor([[-0.5000,  0.5000],\n",
      "        [ 0.2689, -0.2689]]) \n",
      "x\n",
      " tensor([[0.5000, 0.5000],\n",
      "        [0.2689, 0.7311]])\n"
     ]
    }
   ],
   "source": [
    "# 和pytorch对比，看看那一步的梯度计算不符合\n",
    "\n",
    "x = torch.tensor(a, requires_grad=True, dtype=torch.float32)\n",
    "z2 = torch.tensor(a, requires_grad=True, dtype=torch.float32)\n",
    "z1 = torch.tensor(a, requires_grad=True, dtype=torch.float32)\n",
    "print(x)\n",
    "\n",
    "if axis == None:\n",
    "    max_Z1 = torch.max(x)\n",
    "    max_Z2 = max_Z1\n",
    "\n",
    "else:\n",
    "   \n",
    "    max_Z2 = torch.max(z2, dim=axis, keepdim=True).values.broadcast_to(x.shape)\n",
    "    mask = torch.max(z2, dim=axis, keepdim=True).indices\n",
    "    print(\"z2\", z2)\n",
    "    print(\"max mask\", mask)\n",
    "    max_Z1 = torch.max(z1, axis=axis, keepdims=keepdims).values\n",
    "    \n",
    "    \n",
    "\n",
    "max_Z1.retain_grad()\n",
    "max_Z2.retain_grad()\n",
    "\n",
    "yminus = x-max_Z2\n",
    "yexp = torch.exp(yminus)\n",
    "ysum = torch.sum(yexp, dim=axis, keepdims=keepdims)\n",
    "y = torch.log(ysum) + max_Z1\n",
    "\n",
    "yminus.retain_grad()\n",
    "yexp.retain_grad()\n",
    "ysum.retain_grad()\n",
    "y.retain_grad()\n",
    "\n",
    "torch.sum(y).backward()\n",
    "\n",
    "print(\"\\nops.logsumexp\",\n",
    "        \"\\nd_log\\n\", ysum.grad,\n",
    "        \"\\nd_sum\\n\", yexp.grad,\n",
    "        \"\\nd_exp\\n\", yminus.grad,\n",
    "        \"\\ndz1\\n\", z1.grad,\n",
    "         \"\\ndz\\n\",x.grad,\n",
    "        \"\\ndzmax\\n\", z2.grad,\n",
    "        \"\\ndz2\\n\", yminus.grad+z2.grad,\n",
    "        \"\\nx\\n\", x.grad+z1.grad+z2.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
